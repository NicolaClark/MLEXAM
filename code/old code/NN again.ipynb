{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4fe352be",
    "execution_start": 1640545625376,
    "execution_millis": 1125,
    "cell_id": "00000-722d2436-ab1c-46f6-bb2b-4761c927f7f8",
    "deepnote_cell_type": "code"
   },
   "source": "import pandas\nimport numpy as np\nimport random\nimport math\nfrom sklearn.preprocessing import StandardScaler",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "96f61a17",
    "execution_start": 1640545626542,
    "execution_millis": 13,
    "cell_id": "00001-bfe2ba00-4996-4ac0-b0b8-4c932e2c73e3",
    "deepnote_cell_type": "code"
   },
   "source": "test=pandas.read_csv(\"../data/df_test.csv\")\ntrain=pandas.read_csv(\"../data/df_train.csv\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "31e154a8",
    "execution_start": 1640545626565,
    "execution_millis": 12,
    "cell_id": "00002-c0844d64-b206-446a-ab32-bb2c6239ecf6",
    "deepnote_cell_type": "code"
   },
   "source": "def matrix_data(tt): \n    tt_nl=tt.loc[:, tt.columns != \"type\"]\n    tt_l=tt.loc[:, tt.columns == \"type\"]\n    thing=[[adiff(float(j)) for j in i] for i in tt_nl.values]\n    return(thing,tt_l)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "74267d7c",
    "execution_start": 1640545626586,
    "execution_millis": 34,
    "deepnote_output_heights": [
     21.1875
    ],
    "cell_id": "00003-1b6348c6-607d-4c0e-bd55-93ac390c95b9",
    "deepnote_cell_type": "code"
   },
   "source": "train.shape",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "(149, 10)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9a5e960",
    "execution_start": 1640545626618,
    "execution_millis": 17,
    "cell_id": "00004-cdd1e53d-d305-44f7-812f-c9948191671b",
    "deepnote_cell_type": "code"
   },
   "source": "from collections import Counter",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e10a4319",
    "execution_start": 1640545626645,
    "execution_millis": 12,
    "cell_id": "00005-6e650a0e-f9b0-4d5f-b1b5-1e16267d48df",
    "deepnote_cell_type": "code"
   },
   "source": "print(Counter(test[\"type\"]))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Counter({2: 23, 1: 21, 7: 9, 3: 5, 5: 4, 6: 3})\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bdd8351c",
    "execution_start": 1640545626667,
    "execution_millis": 10,
    "cell_id": "00006-28023e78-7b4a-4a36-a67a-21bf9da071c2",
    "deepnote_cell_type": "code"
   },
   "source": "##normalise data before ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d9505f21",
    "execution_start": 1640545626687,
    "execution_millis": 8,
    "deepnote_output_heights": [
     78.765625
    ],
    "cell_id": "00007-7fde1224-5e11-4b55-9b61-619a6a4acbde",
    "deepnote_cell_type": "code"
   },
   "source": "def next_layer(previous_layer,relevant_weights):\n    bias=0.5\n    train_nl,train_l=matrix_data(train)\n    weights=np.random.rand(train_nl.shape[1],10)\n    activation(train_nl@weights+bias)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c99cfbf0",
    "execution_start": 1640546933009,
    "execution_millis": 27,
    "deepnote_output_heights": [
     78.71875
    ],
    "cell_id": "00008-c57b9bd1-a583-43a4-a4a7-0a6ea555cdb4",
    "deepnote_cell_type": "code"
   },
   "source": "import traceback\nclass adiff:\n    \n    def __init__(self, value, parents=None):\n        try:\n            assert type(value) in {float, int}, \"Numbers please\"\n        except AssertionError:\n            print(traceback.format_exc()) \n            print(type(value))           \n        self.val = value\n        self.gradient = 0.0\n        self.parents = parents\n        if parents == None:\n            self.parents = []\n\n    \"\"\"The backprop, from Rasmusbergpalm's github\"\"\"\n    # def backprop(self, bp):\n    #     self.grad += bp\n    #     for parent, grad in self.parents:\n    #         parent.backprop(grad * bp)\n    #     return self\n    def backprop(self, value):\n        self.gradient+= value\n        for parent, gradient in self.parents:\n            parent.backprop(gradient * value)\n    \n    def backward(self):\n        self.backprop(1.0)\n\n    def __add__(self, o_value):\n        n_value = self.val + o_value.val\n        return adiff(n_value, [(self, 1.0), (o_value, 1.0)])\n\n    def __mul__(self, o_value):\n        n_value = self.val * o_value.val\n        return adiff(n_value, [(self, o_value.val), (o_value, self.val)])\n\n    def __sub__(self, o_value):\n        n_value = adiff(self.val - o_value.val, [(self, 1.0), (o_value, 1.0)])\n        return n_value\n        \n    def __pow__(self, o_value):\n        n_value = self.val**o_value.val\n        return adiff(n_value, [(self, o_value.val*self.val**(o_value.val-1.0)), (o_value, n_value*math.log(self.val))])\n    \n    def __truediv__(self, o_value):\n        n_value = self.val/o_value.val\n        return adiff(n_value,[(self,1.0/o_value.val), (o_value,-self.val/o_value.val**2)])##!!!!!!\n\n    #Returning a f-string, with the value and gradient\n    def __repr__(self):\n        return (f\"adiff value = {self.val}, parents = {len(self.parents)}, gradient = {self.gradient}\")\n\n    def e(self):\n        n_value=float(np.exp(self.val))\n        return adiff(n_value, [(self, n_value)])\n    \n    def relu(self,data):\n        return [[adiff(j.val,[(j,1.0)]) if j.val>0 else adiff(0,[(j,0.0)]) for j in i] for i in data]    \n\n    def softmax(self,data):\n        values=[[adiff(item.val) for item in row] for row in data]\n        sums=[]\n        for row in values:\n            current_sum = adiff(0.0)\n            for value in row:\n                current_sum += value.e()\n            sums.append(current_sum)\n        return [[(data[ri][ci]).e()/sums[ri] for ci in range(len(data[0]))]for ri in range(len(data))]\n\n    def sigmoid(self, data):\n        #print(\"in sigmoid\",data)\n        thing=[]\n        for i in data:\n            #print(\"i\",i)\n            thing2=[]\n            for j in i:\n                # print(\"heyo\")\n                #print(j.e())\n                #print(adiff(1.0)/(adiff(1.0)+j.e()))\n                # print(\"this wont print\")\n                thing2.append(adiff(1.0)/(adiff(1.0)+j.e()))\n            thing.append(thing2)\n        return thing #[[adiff(1.0)/(adiff(1.0)+j.e()) for j in i] for i in data] \n## 1.0 / (1.0 + np.exp(-data))\n##sigmoid \n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cdd28849",
    "execution_start": 1640546934582,
    "execution_millis": 23,
    "deepnote_output_heights": [
     78.765625
    ],
    "cell_id": "00009-9330d60b-1a0b-4a8c-ae23-9f0e342d2e5b",
    "deepnote_cell_type": "code"
   },
   "source": "class network:\n    def __init__(self, layers_info,activate = \"sigmoid\"):\n        #self.n_features = n_features\n        self.bias = 0.5\n        self.layers_info = layers_info\n        self.Network=[]\n        self.activate=activate\n    \n    def forward_pass(self,input_data):\n        for row in range(len(input_data)):#add a column of 1s to add the bias during matrix multiplicaiton\n            input_data[row].append(adiff(1.0))\n        for l_info in self.layers_info:    #create new layers \n            new_layer = layer(l_info, len(input_data[1]),self.activate)\n            new_layer.calculation(input_data)\n            self.Network.append(new_layer)\n            input_data = new_layer.next_layer_input\n        output_layer= layer(6, len(input_data[1]),\"softmax\")\n        output_layer.calculation(input_data)\n        self.Network.append(output_layer)\n\n    def predict(self,data):\n        for i in self.Network:\n            i.calculation(data)\n            data=i.next_layer_input\n        values=[[item.val for item in row] for row in data]\n        print([sum(row)for row in values])\n        return np.argmax(values,axis=1)\n            \n    def mse_loss(self,y_true, y_pred):\n        return ((y_true-y_pred)**2).mean()\n        \n    def get_layer(self, i): #do we need this?\n        return self.network[i]\n    \n\nclass layer:\n    def __init__(self,number_of_neurons, n_prev_neurons,activate):\n        self.n = number_of_neurons\n        self.weights = [[adiff(random.random()) for i in range(number_of_neurons)] for _ in range(n_prev_neurons+1)]\n        self.next_layer_input = None\n        self.activate=activate\n    \n    def activation(self,data):\n        if self.activate == \"ReLU\": #check if working later\n            return adiff.relu(self,data)##is self needed here check later\n        elif self.activate == \"sigmoid\":\n            return  adiff.sigmoid(self,data)\n        elif self.activate == \"softmax\":\n            return adiff.softmax(self,data)\n            return np.exp(data)/(np.exp(data).sum(axis=1).reshape(-1,1))\n        else:\n            print(\"invalid activaiton function name\")\n        #more here if needed\n        #choose activation function here\n\n    def _dot_llist(self,llist1,llist2):\n        dot_product = [[0.0 for i in range(len(llist2[0]))] for j in range(len(llist1))]\n        for row in range(len(llist1)):\n            for column in range(len(llist2[0])):\n                a = llist1[row]\n                b = [l2row[column] for l2row in llist2]\n                sum_ = adiff(0.0)\n                for f in a:\n                    for g in b:\n                        sum_ += f * g\n                dot_product[row][column]=sum_\n        return dot_product\n\n    def calculation(self, data):\n        self.next_layer_input = self.activation(self._dot_llist(data,self.weights))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a8438802",
    "execution_start": 1640547341797,
    "execution_millis": 306,
    "deepnote_output_heights": [
     611,
     611
    ],
    "cell_id": "00011-96b1f7a4-d2b9-4e0f-9f65-d7278e0d551e",
    "deepnote_cell_type": "code"
   },
   "source": "norm = StandardScaler()\ntt_nl=train.loc[:, train.columns != \"type\"]\nx = norm.fit_transform(tt_nl)#do this before making adiff later\nx=[[adiff(float(j)) for j in i] for i in x]\ntestingthing=network([2,3],\"sigmoid\")\ntestingthing.forward_pass(x)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "63f3838a",
    "execution_start": 1640547343531,
    "execution_millis": 1141,
    "deepnote_output_heights": [
     null,
     136.359375
    ],
    "cell_id": "00013-195f297f-064a-4f8e-943f-fd4df70f0c7e",
    "deepnote_cell_type": "code"
   },
   "source": "testingthing.predict(x) #predicted labels",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[1.0, 1.0000000000000002, 1.0, 1.0000000000000002, 0.9999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999999999999, 1.0, 1.0, 0.9999999999999999, 0.9999999999999999, 1.0, 1.0, 1.0, 1.0000000000000002, 1.0, 0.9999999999999998, 0.9999999999999999, 1.0, 0.9999999999999999, 1.0, 1.0, 1.0000000000000002, 0.9999999999999999, 1.0, 0.9999999999999998, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999999999998, 1.0, 0.9999999999999998, 1.0, 1.0, 0.9999999999999998, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0000000000000002, 1.0, 1.0, 1.0, 0.9999999999999998, 0.9999999999999999, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0, 1.0000000000000002, 0.9999999999999999, 1.0, 1.0, 1.0, 1.0000000000000002, 0.9999999999999998, 1.0, 1.0, 1.0, 0.9999999999999999, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0, 0.9999999999999999, 1.0, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0000000000000002, 0.9999999999999999, 1.0, 1.0, 1.0, 1.0, 0.9999999999999999, 0.9999999999999999, 1.0, 1.0, 1.0, 0.9999999999999998, 1.0000000000000002, 1.0000000000000002, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999999999999, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0000000000000002, 1.0000000000000002, 1.0, 1.0, 1.0000000000000002, 1.0, 1.0, 0.9999999999999999, 1.0, 0.9999999999999999, 0.9999999999999999, 1.0, 1.0000000000000002, 1.0, 1.0000000000000002, 0.9999999999999999, 1.0, 1.0000000000000002, 1.0, 0.9999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999999999999, 1.0]\n",
     "output_type": "stream",
     "data": {}
    },
    {
     "output_type": "execute_result",
     "execution_count": 56,
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "95d7ef8e",
    "execution_start": 1640547347783,
    "execution_millis": 4,
    "deepnote_output_heights": [
     136.359375
    ],
    "cell_id": "00017-1fa93bae-e948-45d2-95c9-bf2c75a0118e",
    "deepnote_cell_type": "code"
   },
   "source": "np.ravel(matrix_data(train)[1])#real labels ",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 57,
     "data": {
      "text/plain": "array([2, 2, 2, 2, 1, 2, 2, 5, 2, 7, 1, 2, 7, 1, 1, 1, 7, 2, 2, 1, 2, 7,\n       7, 6, 3, 2, 6, 2, 6, 7, 1, 2, 6, 2, 7, 1, 2, 1, 1, 2, 7, 2, 1, 1,\n       2, 1, 3, 2, 2, 2, 2, 1, 7, 7, 1, 5, 1, 1, 1, 1, 1, 3, 1, 2, 3, 7,\n       2, 2, 2, 1, 3, 6, 5, 2, 1, 6, 2, 2, 7, 2, 1, 1, 3, 5, 2, 1, 1, 1,\n       1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 3, 2, 2, 1, 3, 1, 3, 7, 2, 5, 1,\n       2, 1, 1, 1, 7, 3, 1, 3, 5, 2, 2, 5, 7, 2, 1, 7, 2, 3, 7, 7, 2, 1,\n       7, 1, 1, 2, 2, 2, 5, 2, 5, 1, 2, 1, 1, 2, 7, 1, 1])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-06f0b7b6-e312-44d5-a11d-44a083552e05",
    "deepnote_cell_type": "code"
   },
   "source": "#https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\n#^ for later reference for the cross entropy loss we need to use",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "- [ ] check relu works\n- [ ] random seed?\n",
   "metadata": {
    "tags": [],
    "cell_id": "00013-2234a3f7-d2b6-417f-9f95-55c07e13072c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=58866f15-1cff-4fef-9525-5c3070562370' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "e19d44b1-abc9-4e8f-a619-ca6682ef6e2b",
  "deepnote_execution_queue": []
 }
}